{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Basic libraries for data handling and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# üîÑ Progress bar and system tools\n",
    "from tqdm import tqdm  # For tracking progress in loops\n",
    "import sys             # For system-level operations (e.g., flushing output)\n",
    "\n",
    "# ‚öñÔ∏è Resampling techniques from imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler, BorderlineSMOTE  # Over-sampling methods\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss, ClusterCentroids, TomekLinks  # Under-sampling methods\n",
    "\n",
    "# üß™ Model preparation\n",
    "from sklearn.model_selection import train_test_split       # For splitting dataset\n",
    "from sklearn.preprocessing import StandardScaler           # For feature scaling\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # For evaluation\n",
    "\n",
    "# ü§ñ Classification models\n",
    "from sklearn.linear_model import LogisticRegression        # Logistic Regression\n",
    "from sklearn.tree import DecisionTreeClassifier            # Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier  # Tree ensembles\n",
    "from sklearn.neighbors import KNeighborsClassifier         # K-Nearest Neighbors\n",
    "from sklearn.naive_bayes import GaussianNB                 # Naive Bayes\n",
    "\n",
    "# ‚ö° Advanced boosting models\n",
    "from xgboost import XGBClassifier                          # XGBoost\n",
    "from lightgbm import LGBMClassifier                        # LightGBM\n",
    "from catboost import CatBoostClassifier                    # CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a081d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÑ Load preprocessed and encoded datasets\n",
    "train_encoded = pd.read_csv('train_encoded.csv')\n",
    "test_encoded = pd.read_csv('test_encoded.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b66a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'ReimbursementDeductibleRatio' column from both train and test datasets\n",
    "train_encoded.drop(columns='ReimbursementDeductibleRatio', inplace=True)\n",
    "test_encoded.drop(columns='ReimbursementDeductibleRatio', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature and target definition\n",
    "X = train_encoded.drop('PotentialFraud', axis=1)\n",
    "y = train_encoded['PotentialFraud']\n",
    "\n",
    "# split and scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# scaled data to df to have feature names retained\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69394f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling techniques\n",
    "resamplers = {\n",
    "    'SMOTE': SMOTE(random_state=42),\n",
    "    'ADASYN': ADASYN(random_state=42),\n",
    "    'RandomOverSampler': RandomOverSampler(random_state=42),\n",
    "    'BorderlineSMOTE': BorderlineSMOTE(random_state=42),\n",
    "    'RandomUnderSampler': RandomUnderSampler(random_state=42),\n",
    "    'TomekLinks': TomekLinks(),\n",
    "}\n",
    "\n",
    "# Models with proper settings\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(solver='saga', max_iter=2000, random_state=42),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'NaiveBayes': GaussianNB(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', verbosity=0),\n",
    "    'LightGBM': LGBMClassifier(random_state=42, verbose=-1),  \n",
    "    'CatBoost': CatBoostClassifier(verbose=0, random_state=42)  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d23ca65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Preparing balanced datasets...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Balancing Techniques:   0%|          | 0/6 [00:00<?, ?technique/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Applying: SMOTE..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Balancing Techniques:  17%|‚ñà‚ñã        | 1/6 [00:57<04:49, 57.94s/technique]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Applying: ADASYN..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Balancing Techniques:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [05:40<12:40, 190.06s/technique]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Applying: RandomOverSampler..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Balancing Techniques:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [05:40<05:10, 103.45s/technique]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Applying: BorderlineSMOTE..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Balancing Techniques:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [09:41<05:15, 157.69s/technique]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Applying: RandomUnderSampler..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Balancing Techniques:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [09:41<01:40, 100.92s/technique]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Applying: TomekLinks..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Balancing Techniques: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [18:28<00:00, 184.67s/technique]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Balanced datasets ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare balanced datasets with detailed progress and logging\n",
    "balanced_data = {}\n",
    "print(\"‚öôÔ∏è Preparing balanced datasets...\\n\")\n",
    "\n",
    "# Initialize progress bar\n",
    "for name, sampler in tqdm(resamplers.items(), desc=\"Balancing Techniques\", unit=\"technique\", total=len(resamplers)):\n",
    "    sys.stdout.write(f\"\\rüîÑ Applying: {name}...\") \n",
    "    sys.stdout.flush()  \n",
    "    X_res, y_res = sampler.fit_resample(X_train_scaled_df, y_train)\n",
    "    balanced_data[name] = (X_res, y_res)\n",
    "\n",
    "print(\"\\n‚úÖ Balanced datasets ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e02df4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Starting model evaluation on all balanced datasets...\n",
      "\n",
      "\n",
      "üìä Evaluating Models for: SMOTE\n",
      "--------------------------------------------------\n",
      "\n",
      "‚û°Ô∏è Training model: LogisticRegression\n",
      "‚úÖ Accuracy: 0.7949\n",
      "\n",
      "üìù Classification Report for LogisticRegression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83    103507\n",
      "           1       0.73      0.73      0.73     63687\n",
      "\n",
      "    accuracy                           0.79    167194\n",
      "   macro avg       0.78      0.78      0.78    167194\n",
      "weighted avg       0.79      0.79      0.79    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for LogisticRegression (SMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               86568               16939\n",
      "True Positive               17348               46339\n",
      "\n",
      "‚û°Ô∏è Training model: DecisionTree\n",
      "‚úÖ Accuracy: 0.9862\n",
      "\n",
      "üìù Classification Report for DecisionTree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99    103507\n",
      "           1       0.97      0.99      0.98     63687\n",
      "\n",
      "    accuracy                           0.99    167194\n",
      "   macro avg       0.98      0.99      0.99    167194\n",
      "weighted avg       0.99      0.99      0.99    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for DecisionTree (SMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              101873                1634\n",
      "True Positive                 678               63009\n",
      "\n",
      "‚û°Ô∏è Training model: RandomForest\n",
      "‚úÖ Accuracy: 0.9280\n",
      "\n",
      "üìù Classification Report for RandomForest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94    103507\n",
      "           1       0.96      0.84      0.90     63687\n",
      "\n",
      "    accuracy                           0.93    167194\n",
      "   macro avg       0.94      0.91      0.92    167194\n",
      "weighted avg       0.93      0.93      0.93    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for RandomForest (SMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              101553                1954\n",
      "True Positive               10081               53606\n",
      "\n",
      "‚û°Ô∏è Training model: GradientBoosting\n",
      "‚úÖ Accuracy: 0.8789\n",
      "\n",
      "üìù Classification Report for GradientBoosting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91    103507\n",
      "           1       0.92      0.75      0.82     63687\n",
      "\n",
      "    accuracy                           0.88    167194\n",
      "   macro avg       0.89      0.85      0.87    167194\n",
      "weighted avg       0.88      0.88      0.88    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for GradientBoosting (SMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               99318                4189\n",
      "True Positive               16064               47623\n",
      "\n",
      "‚û°Ô∏è Training model: AdaBoost\n",
      "‚úÖ Accuracy: 0.8365\n",
      "\n",
      "üìù Classification Report for AdaBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88    103507\n",
      "           1       0.97      0.59      0.73     63687\n",
      "\n",
      "    accuracy                           0.84    167194\n",
      "   macro avg       0.88      0.79      0.81    167194\n",
      "weighted avg       0.86      0.84      0.83    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for AdaBoost (SMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              102141                1366\n",
      "True Positive               25963               37724\n",
      "\n",
      "‚û°Ô∏è Training model: KNN\n",
      "‚úÖ Accuracy: 0.6830\n",
      "\n",
      "üìù Classification Report for KNN:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73    103507\n",
      "           1       0.57      0.66      0.61     63687\n",
      "\n",
      "    accuracy                           0.68    167194\n",
      "   macro avg       0.67      0.68      0.67    167194\n",
      "weighted avg       0.69      0.68      0.69    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for KNN (SMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               72171               31336\n",
      "True Positive               21670               42017\n",
      "\n",
      "‚û°Ô∏è Training model: NaiveBayes\n",
      "‚úÖ Accuracy: 0.8076\n",
      "\n",
      "üìù Classification Report for NaiveBayes:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85    103507\n",
      "           1       0.79      0.67      0.73     63687\n",
      "\n",
      "    accuracy                           0.81    167194\n",
      "   macro avg       0.80      0.78      0.79    167194\n",
      "weighted avg       0.81      0.81      0.80    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for NaiveBayes (SMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               92303               11204\n",
      "True Positive               20969               42718\n",
      "\n",
      "‚û°Ô∏è Training model: XGBoost\n",
      "‚úÖ Accuracy: 0.9619\n",
      "\n",
      "üìù Classification Report for XGBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    103507\n",
      "           1       0.98      0.92      0.95     63687\n",
      "\n",
      "    accuracy                           0.96    167194\n",
      "   macro avg       0.97      0.95      0.96    167194\n",
      "weighted avg       0.96      0.96      0.96    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for XGBoost (SMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              102308                1199\n",
      "True Positive                5167               58520\n",
      "\n",
      "‚û°Ô∏è Training model: LightGBM\n",
      "‚úÖ Accuracy: 0.9317\n",
      "\n",
      "üìù Classification Report for LightGBM:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95    103507\n",
      "           1       0.96      0.86      0.91     63687\n",
      "\n",
      "    accuracy                           0.93    167194\n",
      "   macro avg       0.94      0.92      0.93    167194\n",
      "weighted avg       0.93      0.93      0.93    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for LightGBM (SMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              101314                2193\n",
      "True Positive                9221               54466\n",
      "\n",
      "‚û°Ô∏è Training model: CatBoost\n",
      "‚úÖ Accuracy: 0.9910\n",
      "\n",
      "üìù Classification Report for CatBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    103507\n",
      "           1       1.00      0.98      0.99     63687\n",
      "\n",
      "    accuracy                           0.99    167194\n",
      "   macro avg       0.99      0.99      0.99    167194\n",
      "weighted avg       0.99      0.99      0.99    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for CatBoost (SMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              103414                  93\n",
      "True Positive                1413               62274\n",
      "\n",
      "üìä Evaluating Models for: ADASYN\n",
      "--------------------------------------------------\n",
      "\n",
      "‚û°Ô∏è Training model: LogisticRegression\n",
      "‚úÖ Accuracy: 0.7873\n",
      "\n",
      "üìù Classification Report for LogisticRegression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83    103507\n",
      "           1       0.71      0.74      0.73     63687\n",
      "\n",
      "    accuracy                           0.79    167194\n",
      "   macro avg       0.77      0.78      0.78    167194\n",
      "weighted avg       0.79      0.79      0.79    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for LogisticRegression (ADASYN):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               84362               19145\n",
      "True Positive               16415               47272\n",
      "\n",
      "‚û°Ô∏è Training model: DecisionTree\n",
      "‚úÖ Accuracy: 0.9844\n",
      "\n",
      "üìù Classification Report for DecisionTree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99    103507\n",
      "           1       0.97      0.99      0.98     63687\n",
      "\n",
      "    accuracy                           0.98    167194\n",
      "   macro avg       0.98      0.99      0.98    167194\n",
      "weighted avg       0.98      0.98      0.98    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for DecisionTree (ADASYN):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              101627                1880\n",
      "True Positive                 733               62954\n",
      "\n",
      "‚û°Ô∏è Training model: RandomForest\n",
      "‚úÖ Accuracy: 0.9258\n",
      "\n",
      "üìù Classification Report for RandomForest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94    103507\n",
      "           1       0.96      0.84      0.90     63687\n",
      "\n",
      "    accuracy                           0.93    167194\n",
      "   macro avg       0.93      0.91      0.92    167194\n",
      "weighted avg       0.93      0.93      0.92    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for RandomForest (ADASYN):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              101274                2233\n",
      "True Positive               10170               53517\n",
      "\n",
      "‚û°Ô∏è Training model: GradientBoosting\n",
      "‚úÖ Accuracy: 0.8666\n",
      "\n",
      "üìù Classification Report for GradientBoosting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90    103507\n",
      "           1       0.87      0.76      0.81     63687\n",
      "\n",
      "    accuracy                           0.87    167194\n",
      "   macro avg       0.87      0.85      0.85    167194\n",
      "weighted avg       0.87      0.87      0.86    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for GradientBoosting (ADASYN):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               96414                7093\n",
      "True Positive               15209               48478\n",
      "\n",
      "‚û°Ô∏è Training model: AdaBoost\n",
      "‚úÖ Accuracy: 0.8363\n",
      "\n",
      "üìù Classification Report for AdaBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88    103507\n",
      "           1       0.92      0.62      0.74     63687\n",
      "\n",
      "    accuracy                           0.84    167194\n",
      "   macro avg       0.86      0.80      0.81    167194\n",
      "weighted avg       0.85      0.84      0.83    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for AdaBoost (ADASYN):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              100225                3282\n",
      "True Positive               24092               39595\n",
      "\n",
      "‚û°Ô∏è Training model: KNN\n",
      "‚úÖ Accuracy: 0.6635\n",
      "\n",
      "üìù Classification Report for KNN:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.64      0.70    103507\n",
      "           1       0.55      0.70      0.61     63687\n",
      "\n",
      "    accuracy                           0.66    167194\n",
      "   macro avg       0.66      0.67      0.66    167194\n",
      "weighted avg       0.69      0.66      0.67    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for KNN (ADASYN):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               66304               37203\n",
      "True Positive               19065               44622\n",
      "\n",
      "‚û°Ô∏è Training model: NaiveBayes\n",
      "‚úÖ Accuracy: 0.8067\n",
      "\n",
      "üìù Classification Report for NaiveBayes:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85    103507\n",
      "           1       0.78      0.68      0.73     63687\n",
      "\n",
      "    accuracy                           0.81    167194\n",
      "   macro avg       0.80      0.78      0.79    167194\n",
      "weighted avg       0.81      0.81      0.80    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for NaiveBayes (ADASYN):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               91626               11881\n",
      "True Positive               20434               43253\n",
      "\n",
      "‚û°Ô∏è Training model: XGBoost\n",
      "‚úÖ Accuracy: 0.9604\n",
      "\n",
      "üìù Classification Report for XGBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    103507\n",
      "           1       0.98      0.92      0.95     63687\n",
      "\n",
      "    accuracy                           0.96    167194\n",
      "   macro avg       0.96      0.95      0.96    167194\n",
      "weighted avg       0.96      0.96      0.96    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for XGBoost (ADASYN):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              102251                1256\n",
      "True Positive                5368               58319\n",
      "\n",
      "‚û°Ô∏è Training model: LightGBM\n",
      "‚úÖ Accuracy: 0.9304\n",
      "\n",
      "üìù Classification Report for LightGBM:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95    103507\n",
      "           1       0.96      0.85      0.90     63687\n",
      "\n",
      "    accuracy                           0.93    167194\n",
      "   macro avg       0.94      0.92      0.92    167194\n",
      "weighted avg       0.93      0.93      0.93    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for LightGBM (ADASYN):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              101141                2366\n",
      "True Positive                9274               54413\n",
      "\n",
      "‚û°Ô∏è Training model: CatBoost\n",
      "‚úÖ Accuracy: 0.9903\n",
      "\n",
      "üìù Classification Report for CatBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    103507\n",
      "           1       1.00      0.98      0.99     63687\n",
      "\n",
      "    accuracy                           0.99    167194\n",
      "   macro avg       0.99      0.99      0.99    167194\n",
      "weighted avg       0.99      0.99      0.99    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for CatBoost (ADASYN):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              103387                 120\n",
      "True Positive                1500               62187\n",
      "\n",
      "üìä Evaluating Models for: RandomOverSampler\n",
      "--------------------------------------------------\n",
      "\n",
      "‚û°Ô∏è Training model: LogisticRegression\n",
      "‚úÖ Accuracy: 0.7939\n",
      "\n",
      "üìù Classification Report for LogisticRegression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83    103507\n",
      "           1       0.73      0.73      0.73     63687\n",
      "\n",
      "    accuracy                           0.79    167194\n",
      "   macro avg       0.78      0.78      0.78    167194\n",
      "weighted avg       0.79      0.79      0.79    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for LogisticRegression (RandomOverSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               86318               17189\n",
      "True Positive               17263               46424\n",
      "\n",
      "‚û°Ô∏è Training model: DecisionTree\n",
      "‚úÖ Accuracy: 0.9927\n",
      "\n",
      "üìù Classification Report for DecisionTree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    103507\n",
      "           1       0.99      0.99      0.99     63687\n",
      "\n",
      "    accuracy                           0.99    167194\n",
      "   macro avg       0.99      0.99      0.99    167194\n",
      "weighted avg       0.99      0.99      0.99    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for DecisionTree (RandomOverSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              102862                 645\n",
      "True Positive                 573               63114\n",
      "\n",
      "‚û°Ô∏è Training model: RandomForest\n",
      "‚úÖ Accuracy: 0.9444\n",
      "\n",
      "üìù Classification Report for RandomForest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96    103507\n",
      "           1       0.97      0.88      0.92     63687\n",
      "\n",
      "    accuracy                           0.94    167194\n",
      "   macro avg       0.95      0.93      0.94    167194\n",
      "weighted avg       0.95      0.94      0.94    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for RandomForest (RandomOverSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              102057                1450\n",
      "True Positive                7839               55848\n",
      "\n",
      "‚û°Ô∏è Training model: GradientBoosting\n",
      "‚úÖ Accuracy: 0.8898\n",
      "\n",
      "üìù Classification Report for GradientBoosting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92    103507\n",
      "           1       0.93      0.77      0.84     63687\n",
      "\n",
      "    accuracy                           0.89    167194\n",
      "   macro avg       0.90      0.87      0.88    167194\n",
      "weighted avg       0.89      0.89      0.89    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for GradientBoosting (RandomOverSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               99621                3886\n",
      "True Positive               14544               49143\n",
      "\n",
      "‚û°Ô∏è Training model: AdaBoost\n",
      "‚úÖ Accuracy: 0.8373\n",
      "\n",
      "üìù Classification Report for AdaBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88    103507\n",
      "           1       0.97      0.59      0.73     63687\n",
      "\n",
      "    accuracy                           0.84    167194\n",
      "   macro avg       0.88      0.79      0.81    167194\n",
      "weighted avg       0.86      0.84      0.83    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for AdaBoost (RandomOverSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              102290                1217\n",
      "True Positive               25982               37705\n",
      "\n",
      "‚û°Ô∏è Training model: KNN\n",
      "‚úÖ Accuracy: 0.6873\n",
      "\n",
      "üìù Classification Report for KNN:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74    103507\n",
      "           1       0.58      0.62      0.60     63687\n",
      "\n",
      "    accuracy                           0.69    167194\n",
      "   macro avg       0.67      0.67      0.67    167194\n",
      "weighted avg       0.69      0.69      0.69    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for KNN (RandomOverSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               75310               28197\n",
      "True Positive               24089               39598\n",
      "\n",
      "‚û°Ô∏è Training model: NaiveBayes\n",
      "‚úÖ Accuracy: 0.8020\n",
      "\n",
      "üìù Classification Report for NaiveBayes:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85    103507\n",
      "           1       0.78      0.67      0.72     63687\n",
      "\n",
      "    accuracy                           0.80    167194\n",
      "   macro avg       0.80      0.78      0.78    167194\n",
      "weighted avg       0.80      0.80      0.80    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for NaiveBayes (RandomOverSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               91390               12117\n",
      "True Positive               20982               42705\n",
      "\n",
      "‚û°Ô∏è Training model: XGBoost\n",
      "‚úÖ Accuracy: 0.9815\n",
      "\n",
      "üìù Classification Report for XGBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99    103507\n",
      "           1       0.99      0.96      0.98     63687\n",
      "\n",
      "    accuracy                           0.98    167194\n",
      "   macro avg       0.98      0.98      0.98    167194\n",
      "weighted avg       0.98      0.98      0.98    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for XGBoost (RandomOverSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              102824                 683\n",
      "True Positive                2409               61278\n",
      "\n",
      "‚û°Ô∏è Training model: LightGBM\n",
      "‚úÖ Accuracy: 0.9533\n",
      "\n",
      "üìù Classification Report for LightGBM:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96    103507\n",
      "           1       0.97      0.91      0.94     63687\n",
      "\n",
      "    accuracy                           0.95    167194\n",
      "   macro avg       0.96      0.94      0.95    167194\n",
      "weighted avg       0.95      0.95      0.95    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for LightGBM (RandomOverSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              101456                2051\n",
      "True Positive                5759               57928\n",
      "\n",
      "‚û°Ô∏è Training model: CatBoost\n",
      "‚úÖ Accuracy: 0.9965\n",
      "\n",
      "üìù Classification Report for CatBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    103507\n",
      "           1       1.00      0.99      1.00     63687\n",
      "\n",
      "    accuracy                           1.00    167194\n",
      "   macro avg       1.00      1.00      1.00    167194\n",
      "weighted avg       1.00      1.00      1.00    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for CatBoost (RandomOverSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              103398                 109\n",
      "True Positive                 484               63203\n",
      "\n",
      "üìä Evaluating Models for: BorderlineSMOTE\n",
      "--------------------------------------------------\n",
      "\n",
      "‚û°Ô∏è Training model: LogisticRegression\n",
      "‚úÖ Accuracy: 0.7916\n",
      "\n",
      "üìù Classification Report for LogisticRegression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83    103507\n",
      "           1       0.72      0.74      0.73     63687\n",
      "\n",
      "    accuracy                           0.79    167194\n",
      "   macro avg       0.78      0.78      0.78    167194\n",
      "weighted avg       0.79      0.79      0.79    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for LogisticRegression (BorderlineSMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               85506               18001\n",
      "True Positive               16848               46839\n",
      "\n",
      "‚û°Ô∏è Training model: DecisionTree\n",
      "‚úÖ Accuracy: 0.9874\n",
      "\n",
      "üìù Classification Report for DecisionTree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    103507\n",
      "           1       0.98      0.99      0.98     63687\n",
      "\n",
      "    accuracy                           0.99    167194\n",
      "   macro avg       0.99      0.99      0.99    167194\n",
      "weighted avg       0.99      0.99      0.99    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for DecisionTree (BorderlineSMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              101983                1524\n",
      "True Positive                 588               63099\n",
      "\n",
      "‚û°Ô∏è Training model: RandomForest\n",
      "‚úÖ Accuracy: 0.9246\n",
      "\n",
      "üìù Classification Report for RandomForest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94    103507\n",
      "           1       0.96      0.83      0.89     63687\n",
      "\n",
      "    accuracy                           0.92    167194\n",
      "   macro avg       0.93      0.91      0.92    167194\n",
      "weighted avg       0.93      0.92      0.92    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for RandomForest (BorderlineSMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              101458                2049\n",
      "True Positive               10563               53124\n",
      "\n",
      "‚û°Ô∏è Training model: GradientBoosting\n",
      "‚úÖ Accuracy: 0.8716\n",
      "\n",
      "üìù Classification Report for GradientBoosting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90    103507\n",
      "           1       0.88      0.76      0.82     63687\n",
      "\n",
      "    accuracy                           0.87    167194\n",
      "   macro avg       0.87      0.85      0.86    167194\n",
      "weighted avg       0.87      0.87      0.87    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for GradientBoosting (BorderlineSMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               97141                6366\n",
      "True Positive               15110               48577\n",
      "\n",
      "‚û°Ô∏è Training model: AdaBoost\n",
      "‚úÖ Accuracy: 0.8366\n",
      "\n",
      "üìù Classification Report for AdaBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88    103507\n",
      "           1       0.92      0.62      0.74     63687\n",
      "\n",
      "    accuracy                           0.84    167194\n",
      "   macro avg       0.86      0.80      0.81    167194\n",
      "weighted avg       0.85      0.84      0.83    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for AdaBoost (BorderlineSMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              100217                3290\n",
      "True Positive               24032               39655\n",
      "\n",
      "‚û°Ô∏è Training model: KNN\n",
      "‚úÖ Accuracy: 0.6673\n",
      "\n",
      "üìù Classification Report for KNN:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.66      0.71    103507\n",
      "           1       0.55      0.68      0.61     63687\n",
      "\n",
      "    accuracy                           0.67    167194\n",
      "   macro avg       0.66      0.67      0.66    167194\n",
      "weighted avg       0.69      0.67      0.67    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for KNN (BorderlineSMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               68218               35289\n",
      "True Positive               20333               43354\n",
      "\n",
      "‚û°Ô∏è Training model: NaiveBayes\n",
      "‚úÖ Accuracy: 0.8092\n",
      "\n",
      "üìù Classification Report for NaiveBayes:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85    103507\n",
      "           1       0.79      0.68      0.73     63687\n",
      "\n",
      "    accuracy                           0.81    167194\n",
      "   macro avg       0.80      0.78      0.79    167194\n",
      "weighted avg       0.81      0.81      0.81    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for NaiveBayes (BorderlineSMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               91894               11613\n",
      "True Positive               20280               43407\n",
      "\n",
      "‚û°Ô∏è Training model: XGBoost\n",
      "‚úÖ Accuracy: 0.9639\n",
      "\n",
      "üìù Classification Report for XGBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    103507\n",
      "           1       0.98      0.92      0.95     63687\n",
      "\n",
      "    accuracy                           0.96    167194\n",
      "   macro avg       0.97      0.96      0.96    167194\n",
      "weighted avg       0.96      0.96      0.96    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for XGBoost (BorderlineSMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              102373                1134\n",
      "True Positive                4896               58791\n",
      "\n",
      "‚û°Ô∏è Training model: LightGBM\n",
      "‚úÖ Accuracy: 0.9294\n",
      "\n",
      "üìù Classification Report for LightGBM:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94    103507\n",
      "           1       0.96      0.85      0.90     63687\n",
      "\n",
      "    accuracy                           0.93    167194\n",
      "   macro avg       0.94      0.91      0.92    167194\n",
      "weighted avg       0.93      0.93      0.93    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for LightGBM (BorderlineSMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              101269                2238\n",
      "True Positive                9567               54120\n",
      "\n",
      "‚û°Ô∏è Training model: CatBoost\n",
      "‚úÖ Accuracy: 0.9907\n",
      "\n",
      "üìù Classification Report for CatBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    103507\n",
      "           1       1.00      0.98      0.99     63687\n",
      "\n",
      "    accuracy                           0.99    167194\n",
      "   macro avg       0.99      0.99      0.99    167194\n",
      "weighted avg       0.99      0.99      0.99    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for CatBoost (BorderlineSMOTE):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              103416                  91\n",
      "True Positive                1457               62230\n",
      "\n",
      "üìä Evaluating Models for: RandomUnderSampler\n",
      "--------------------------------------------------\n",
      "\n",
      "‚û°Ô∏è Training model: LogisticRegression\n",
      "‚úÖ Accuracy: 0.7935\n",
      "\n",
      "üìù Classification Report for LogisticRegression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83    103507\n",
      "           1       0.73      0.73      0.73     63687\n",
      "\n",
      "    accuracy                           0.79    167194\n",
      "   macro avg       0.78      0.78      0.78    167194\n",
      "weighted avg       0.79      0.79      0.79    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for LogisticRegression (RandomUnderSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               86260               17247\n",
      "True Positive               17278               46409\n",
      "\n",
      "‚û°Ô∏è Training model: DecisionTree\n",
      "‚úÖ Accuracy: 0.9895\n",
      "\n",
      "üìù Classification Report for DecisionTree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    103507\n",
      "           1       0.98      0.99      0.99     63687\n",
      "\n",
      "    accuracy                           0.99    167194\n",
      "   macro avg       0.99      0.99      0.99    167194\n",
      "weighted avg       0.99      0.99      0.99    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for DecisionTree (RandomUnderSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              102382                1125\n",
      "True Positive                 629               63058\n",
      "\n",
      "‚û°Ô∏è Training model: RandomForest\n",
      "‚úÖ Accuracy: 0.9462\n",
      "\n",
      "üìù Classification Report for RandomForest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96    103507\n",
      "           1       0.96      0.89      0.93     63687\n",
      "\n",
      "    accuracy                           0.95    167194\n",
      "   macro avg       0.95      0.94      0.94    167194\n",
      "weighted avg       0.95      0.95      0.95    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for RandomForest (RandomUnderSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              101390                2117\n",
      "True Positive                6882               56805\n",
      "\n",
      "‚û°Ô∏è Training model: GradientBoosting\n",
      "‚úÖ Accuracy: 0.8866\n",
      "\n",
      "üìù Classification Report for GradientBoosting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91    103507\n",
      "           1       0.93      0.76      0.84     63687\n",
      "\n",
      "    accuracy                           0.89    167194\n",
      "   macro avg       0.90      0.86      0.88    167194\n",
      "weighted avg       0.89      0.89      0.88    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for GradientBoosting (RandomUnderSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               99560                3947\n",
      "True Positive               15007               48680\n",
      "\n",
      "‚û°Ô∏è Training model: AdaBoost\n",
      "‚úÖ Accuracy: 0.8373\n",
      "\n",
      "üìù Classification Report for AdaBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88    103507\n",
      "           1       0.97      0.59      0.73     63687\n",
      "\n",
      "    accuracy                           0.84    167194\n",
      "   macro avg       0.88      0.79      0.81    167194\n",
      "weighted avg       0.86      0.84      0.83    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for AdaBoost (RandomUnderSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              102290                1217\n",
      "True Positive               25982               37705\n",
      "\n",
      "‚û°Ô∏è Training model: KNN\n",
      "‚úÖ Accuracy: 0.6929\n",
      "\n",
      "üìù Classification Report for KNN:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75    103507\n",
      "           1       0.59      0.64      0.61     63687\n",
      "\n",
      "    accuracy                           0.69    167194\n",
      "   macro avg       0.68      0.68      0.68    167194\n",
      "weighted avg       0.70      0.69      0.69    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for KNN (RandomUnderSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               75269               28238\n",
      "True Positive               23115               40572\n",
      "\n",
      "‚û°Ô∏è Training model: NaiveBayes\n",
      "‚úÖ Accuracy: 0.8021\n",
      "\n",
      "üìù Classification Report for NaiveBayes:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85    103507\n",
      "           1       0.78      0.67      0.72     63687\n",
      "\n",
      "    accuracy                           0.80    167194\n",
      "   macro avg       0.80      0.78      0.78    167194\n",
      "weighted avg       0.80      0.80      0.80    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for NaiveBayes (RandomUnderSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               91381               12126\n",
      "True Positive               20961               42726\n",
      "\n",
      "‚û°Ô∏è Training model: XGBoost\n",
      "‚úÖ Accuracy: 0.9809\n",
      "\n",
      "üìù Classification Report for XGBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    103507\n",
      "           1       0.99      0.96      0.97     63687\n",
      "\n",
      "    accuracy                           0.98    167194\n",
      "   macro avg       0.98      0.98      0.98    167194\n",
      "weighted avg       0.98      0.98      0.98    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for XGBoost (RandomUnderSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              102746                 761\n",
      "True Positive                2435               61252\n",
      "\n",
      "‚û°Ô∏è Training model: LightGBM\n",
      "‚úÖ Accuracy: 0.9542\n",
      "\n",
      "üìù Classification Report for LightGBM:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96    103507\n",
      "           1       0.96      0.91      0.94     63687\n",
      "\n",
      "    accuracy                           0.95    167194\n",
      "   macro avg       0.96      0.95      0.95    167194\n",
      "weighted avg       0.95      0.95      0.95    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for LightGBM (RandomUnderSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              101351                2156\n",
      "True Positive                5499               58188\n",
      "\n",
      "‚û°Ô∏è Training model: CatBoost\n",
      "‚úÖ Accuracy: 0.9949\n",
      "\n",
      "üìù Classification Report for CatBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    103507\n",
      "           1       1.00      0.99      0.99     63687\n",
      "\n",
      "    accuracy                           0.99    167194\n",
      "   macro avg       1.00      0.99      0.99    167194\n",
      "weighted avg       0.99      0.99      0.99    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for CatBoost (RandomUnderSampler):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              103336                 171\n",
      "True Positive                 681               63006\n",
      "\n",
      "üìä Evaluating Models for: TomekLinks\n",
      "--------------------------------------------------\n",
      "\n",
      "‚û°Ô∏è Training model: LogisticRegression\n",
      "‚úÖ Accuracy: 0.8151\n",
      "\n",
      "üìù Classification Report for LogisticRegression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.86    103507\n",
      "           1       0.80      0.69      0.74     63687\n",
      "\n",
      "    accuracy                           0.82    167194\n",
      "   macro avg       0.81      0.79      0.80    167194\n",
      "weighted avg       0.81      0.82      0.81    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for LogisticRegression (TomekLinks):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               92417               11090\n",
      "True Positive               19828               43859\n",
      "\n",
      "‚û°Ô∏è Training model: DecisionTree\n",
      "‚úÖ Accuracy: 0.9929\n",
      "\n",
      "üìù Classification Report for DecisionTree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    103507\n",
      "           1       0.99      0.99      0.99     63687\n",
      "\n",
      "    accuracy                           0.99    167194\n",
      "   macro avg       0.99      0.99      0.99    167194\n",
      "weighted avg       0.99      0.99      0.99    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for DecisionTree (TomekLinks):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              102851                 656\n",
      "True Positive                 534               63153\n",
      "\n",
      "‚û°Ô∏è Training model: RandomForest\n",
      "‚úÖ Accuracy: 0.9407\n",
      "\n",
      "üìù Classification Report for RandomForest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95    103507\n",
      "           1       0.97      0.87      0.92     63687\n",
      "\n",
      "    accuracy                           0.94    167194\n",
      "   macro avg       0.95      0.93      0.94    167194\n",
      "weighted avg       0.94      0.94      0.94    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for RandomForest (TomekLinks):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              102010                1497\n",
      "True Positive                8410               55277\n",
      "\n",
      "‚û°Ô∏è Training model: GradientBoosting\n",
      "‚úÖ Accuracy: 0.8819\n",
      "\n",
      "üìù Classification Report for GradientBoosting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91    103507\n",
      "           1       0.94      0.73      0.83     63687\n",
      "\n",
      "    accuracy                           0.88    167194\n",
      "   macro avg       0.90      0.85      0.87    167194\n",
      "weighted avg       0.89      0.88      0.88    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for GradientBoosting (TomekLinks):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              100721                2786\n",
      "True Positive               16953               46734\n",
      "\n",
      "‚û°Ô∏è Training model: AdaBoost\n",
      "‚úÖ Accuracy: 0.8373\n",
      "\n",
      "üìù Classification Report for AdaBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88    103507\n",
      "           1       0.97      0.59      0.73     63687\n",
      "\n",
      "    accuracy                           0.84    167194\n",
      "   macro avg       0.88      0.79      0.81    167194\n",
      "weighted avg       0.86      0.84      0.83    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for AdaBoost (TomekLinks):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              102290                1217\n",
      "True Positive               25982               37705\n",
      "\n",
      "‚û°Ô∏è Training model: KNN\n",
      "‚úÖ Accuracy: 0.7161\n",
      "\n",
      "üìù Classification Report for KNN:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78    103507\n",
      "           1       0.66      0.54      0.59     63687\n",
      "\n",
      "    accuracy                           0.72    167194\n",
      "   macro avg       0.70      0.68      0.69    167194\n",
      "weighted avg       0.71      0.72      0.71    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for KNN (TomekLinks):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               85488               18019\n",
      "True Positive               29449               34238\n",
      "\n",
      "‚û°Ô∏è Training model: NaiveBayes\n",
      "‚úÖ Accuracy: 0.8060\n",
      "\n",
      "üìù Classification Report for NaiveBayes:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85    103507\n",
      "           1       0.80      0.66      0.72     63687\n",
      "\n",
      "    accuracy                           0.81    167194\n",
      "   macro avg       0.80      0.78      0.79    167194\n",
      "weighted avg       0.81      0.81      0.80    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for NaiveBayes (TomekLinks):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative               92936               10571\n",
      "True Positive               21859               41828\n",
      "\n",
      "‚û°Ô∏è Training model: XGBoost\n",
      "‚úÖ Accuracy: 0.9813\n",
      "\n",
      "üìù Classification Report for XGBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99    103507\n",
      "           1       0.99      0.96      0.98     63687\n",
      "\n",
      "    accuracy                           0.98    167194\n",
      "   macro avg       0.98      0.98      0.98    167194\n",
      "weighted avg       0.98      0.98      0.98    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for XGBoost (TomekLinks):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              103141                 366\n",
      "True Positive                2754               60933\n",
      "\n",
      "‚û°Ô∏è Training model: LightGBM\n",
      "‚úÖ Accuracy: 0.9449\n",
      "\n",
      "üìù Classification Report for LightGBM:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96    103507\n",
      "           1       0.98      0.88      0.92     63687\n",
      "\n",
      "    accuracy                           0.94    167194\n",
      "   macro avg       0.95      0.93      0.94    167194\n",
      "weighted avg       0.95      0.94      0.94    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for LightGBM (TomekLinks):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              102075                1432\n",
      "True Positive                7776               55911\n",
      "\n",
      "‚û°Ô∏è Training model: CatBoost\n",
      "‚úÖ Accuracy: 0.9952\n",
      "\n",
      "üìù Classification Report for CatBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    103507\n",
      "           1       1.00      0.99      0.99     63687\n",
      "\n",
      "    accuracy                           1.00    167194\n",
      "   macro avg       1.00      0.99      0.99    167194\n",
      "weighted avg       1.00      1.00      1.00    167194\n",
      "\n",
      "\n",
      "üî¢ Confusion Matrix for CatBoost (TomekLinks):\n",
      "               Predicted Negative  Predicted Positive\n",
      "True Negative              103433                  74\n",
      "True Positive                 735               62952\n",
      "\n",
      "‚úÖ All model evaluations complete.\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print(\"üîç Starting model evaluation on all balanced datasets...\\n\")\n",
    "\n",
    "# For each model and resampling technique\n",
    "for technique_name, (X_bal, y_bal) in balanced_data.items():\n",
    "    print(f\"\\nüìä Evaluating Models for: {technique_name}\\n{'-'*50}\")\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\n‚û°Ô∏è Training model: {model_name}\")\n",
    "        model.fit(X_bal, y_bal)\n",
    "        y_pred = model.predict(X_test_scaled_df) \n",
    "        \n",
    "        # Accuracy score\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"‚úÖ Accuracy: {acc:.4f}\")\n",
    "        \n",
    "        # Classification Report\n",
    "        print(f\"\\nüìù Classification Report for {model_name}:\\n\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Confusion Matrix with proper alignment using pandas\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        cm_df = pd.DataFrame(cm, index=['True Negative', 'True Positive'], columns=['Predicted Negative', 'Predicted Positive'])\n",
    "        print(f\"\\nüî¢ Confusion Matrix for {model_name} ({technique_name}):\")\n",
    "        print(cm_df)\n",
    "\n",
    "print(\"\\n‚úÖ All model evaluations complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
